= Usine Logicielle

Nous mettons en place l'Usine Logicielle pour industrialiser nos développements et notamment accélérer les temps de mises en prod en suivant une démarche de Continuous Delivery : tout commit sur un dépôt GIT d'une application déclenche la construction des binaires de l'application suivi du déploiement de l'application.

Pour ce faire, l'Usine Logicielle fournit des outils pour automatiser la construction des binaires ainsi que des environnements de déploiement.

== Outillage

L'Outillage mis en place permet :

* La gestion des sources des applications
* La construction des binaires de l'application et l'exécution des tests unitaires (via Jenkins)
* L'archivage des binaires (dans Nexus)
* L'analyse qualité des sources (via SonarQube)

=== Gestion des Sources

Les sources sont hébergées dans une Organisation Github https://github.com/SofteamOuest-Opus[dédiée].

Les sources d'une application sont gérées dans un dépôt GIT.

=== Jenkins

Nous utilisons https://jenkins.k8.wildwidewest.xyz[Jenkins] pour orchestrer les BUILDS.

==== Configuration Jenkins

De manière à simplifier au maximum la mise en place de l'Usine Logicielle, le serveur Jenkins est configuré automatiquement, en utilisant https://jenkins.io/projects/jcasc/[Jenkins Configuration as Code].

[source]
....
Scenario: JENKINS_CONF
En tant que Gestionnaire d'Intégration Continue,
Quand j'importe un fichier de configuration du serveur Jenkins
Alors le serveur est correctement configuré
....

La configuration concerne notamment :

* Les comptes utilisateurs
* Les secrets (mot de passe Nexus, token sonarqube)
* Les fichiers de configuration (Gradle, SSH)
* L'import d'organisations GitHub
* L'import de plugins (exemple : JIRA)

==== Jobs Jenkins

De manière à uniformiser nos jobs Jenkins, nous les implémentons via des Jenkinsfile.

Nous implémentons différents types de Jobs, notamment :

* Des Jobs de BUILD pour construire les binaires des applications
* Des Jobs de RELEASE pour figer les versions des applications
* Des Jobs de RUN pour déployer les applications

==== Job de BUILD

Le Job de BUILD d'une application permet de construire les binaires (image Docker) de l'application (en version SNAPSHOT) et déclencher un Job de Déploiement

[source]
....
Scenario: JENKINS_JOB_BUILD
En tant qu'Utilisateur IC,
Quand j'exécute le Job de BUILD d'une application
Alors le job construit et déploie l'image Docker de l'application
Et déclenche le Job du RUN sur l'application
....

RG : Le Job de BUILD est déclenché automatiquement après tout push sur les sources de l'application.

==== Job de RELEASE

Le Job de RELEASE permet de créer une RELEASE des sources et binaires d'une application.

[source]
....
Scenario: JENKINS_JOB_RELEASE
En tant que Responsable Livraison d'une application,
Quand j'exécute le Job de RELEASE de cette application en indiquant la version de RELEASE
Alors le Job construit et déploie l'image Docker de l'application en version RELEASE
Et construit et déploie les jars de l'application en version RELEASE
....

==== Job de RUN

Le Job de RUN permet de déployer une application sur le cluster.

[source]
....
Scenario: JENKINS_JOB_RUN
En tant qu'Utilisateur IC,
Quand j'exécute le Job de RUN en indiquant
* le nom de l'application
* la version de l'application
* la version du package Helm
* l'environnement de déploiement (dev, prod)
Alors l'application est déployée
....

==== Job de FULL-RUN

Le Job de FULL-RUN permet de déployer toutes les applications.

Le Job prend les même paramètres que le Job de RUN (pour chaque application à déployer).

[source]
....
Scenario: JENKINS_JOB_FULL_RUN
En tant qu'Utilisateur IC,
Quand j'exécute le Job de FULL-RUN en indiquant pour chaque application
* le nom de l'application
* la version de l'application
* la version du package Helm
* l'environnement de déploiement (dev, prod)
Alors toutes les applications sont déployées
....

RG : Si le tag de l'image Docker d'une application n'est pas défini, l'application n'est pas déployée.

=== Nexus

Nous utilisons https://Nexus.k8.wildwidewest.xyz/[Nexus] pour archiver les images Docker.

Les accès au serveur Nexus sont authentifiés par login, password.

=== SonarQube

Nous utilisons https://sonarqube.k8.wildwidewest.xyz/[SonarQube] pour analyser la qualité du code développé.

Les accès au serveur SonarQube sont authentifiés par token.

=== JIRA

Nous utilisons https://wildwidewest.atlassian.net[JIRA] pour suivre le développement du Projet.

== Environnements

Nous déployons nos applications dans différents environnements.

* L'environnement de DEV permet de tester la dernière version SNAPSHOT des applications (=> version en cours de développement).
* L'environnement de RE7 permet de tester une version RELEASE avant Mise en Prod (=> version à qualifier).
* L'environnement de PROD correspond à l'environnement utilisé (=> version qualifiée).

De manière à isoler les applications des différents environnements, chaque environnement est matérialisé par un namespace dans le cluster Kubernetes.

=== Accès aux Applications

Le nom de l'environnement apparaît dans l'URL de l'application.

Si le nom de l'application est mon application,

* Si le nom de l'environnement est PROD, l'URL d'accès est https://monapplication.k8.wildwidewest.xyz
* Sinon (le nom de l'environnement est XXX), l'URL d'accès est https://monapplication-XXX.k8.wildwidewest.xyz (=> le nom de l'environnement se retrouve dans l'URL de l'application)

=== Centralisation des Logs

La centralisation des Logs permet d'analyser via une IHM unique les logs de toutes les applications.

Pour simplifier la mise en place, les applications partagent un même format de Logs.

Le format du Log est :

* Niveau de Log : DEBUG, INFO, ERROR
* Message du Log
* Nom de l'application
* Nom de l'environnement
* Id de Correlation du Message
* StackTrace si le message est une exception

=== Monitoring

Le monitoring permet de monitorer l'état du cluster Kubernetes.

Nous monitorons :

* Le CPU (critère à définir)
* Le disque (utilisation > 90 %)

Les alertes de monitoring sont envoyées par email aux membres du projet.

=== Tolérance aux Pannes

Nous gérons deux types de pannes : Les pannes des applications et les pannes du cluster.

==== Pannes des applications

La gestion des pannes des applications est gérée par Kubernetes.

Pour y arriver, Kubernetes se base sur https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[les lignes de vie des applications].

Si la ligne de vie d'une application ne répond pas, Kubernetes se charge de redémarrer l'application.

Chaque application déployée doit donc définir ses lignes de vie.

==== Pannes du Cluster

La gestion des pannes du cluster est gérée par une installation multi-maîtres :

* Pour être tolérant à une panne, il faut 3 maîtres
* Pour être tolérant à deux pannes, il faut 5 maîtres